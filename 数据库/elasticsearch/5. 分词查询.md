在安装时我们安装了ik分词插件

### 设置

使用分词必须要先设置mapping, 在字段中设置分词方式

```
{
		 "type": "text",
		 "analyzer": "ik_max_word" # 分词方式使用细颗粒
}

{
		 "type": "text",
		 "analyzer": "ik_smart" # 分词方式使用颗粒度粗的
}
```

### 查询

**match**知道分词器的存在，会对field进行分词操作，然后再查询,最常见的查询方式

**match_phrase** ES引擎首先分析查询字符串，从分析后的文本中构建短语查询，这意味着必须匹配短语中的所有分词，并且保证各个分词的相对位置不变

```
GET index/type/_search
{
  "query": {
    "match_phrase": {
      "FIELD": "PHRASE"
    }
  }
}
```

**Match_phrase_prefix** 短语前缀查询,类似于数据库中的 like ‘a%’这样的以什么开头的插叙方式,对于中文来说于普通的短语测试没有什么太大的区别

```
GET index/type/_search
{
  "query": {
    "match_phrase_prefix": {
      "FIELD": "PREFIX"
    }
  }
```

**term** term会去倒排索引中寻找确切的term，它并不知道分词器的存在，这种查询适合keyword、numeric、date等明确值的,查询某个字段里含有某个关键词的文档

**terms** : 类似term, 查询某个字段里含有多个关键词的文档

> term和terms主要看数据管理那一节

